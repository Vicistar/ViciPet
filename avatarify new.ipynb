{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avatarify",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vicistar/ViciPet/blob/main/avatarify%20new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEl-Q4OpsLb9"
      },
      "source": [
        "# Avatarify Colab Server\n",
        "\n",
        "This Colab notebook is for running Avatarify rendering server. It allows you to run Avatarify on your computer **without GPU** in this way:\n",
        "\n",
        "1. When this notebook is executed, it starts listening for incoming requests from your computer;\n",
        "1. You start the client on your computer and it connects to the notebook and starts sending requests;\n",
        "1. This notebooks receives the requests from your computer, renders avatar images and sends them back;\n",
        "\n",
        "To this end, all the heavy work is offloaded from your computer to this notebook so you don't need to have a beafy hardware on your PC anymore.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRpMPl7VyeoD"
      },
      "source": [
        "## Start the server\n",
        "Run the cells below (Shift+Enter) sequentially and pay attention to the hints and instructions included in this notebook.\n",
        "\n",
        "At the end you will get a command for running the client on your computer.\n",
        "\n",
        "## Start the client\n",
        "\n",
        "Make sure you have installed the latest version of Avatarify on your computer. Refer to the [README](https://github.com/alievk/avatarify#install) for the instructions.\n",
        "\n",
        "When it's ready execute this notebook and get the command for running the client on your computer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h0f5WQEjgbH"
      },
      "source": [
        "### Technical details\n",
        "\n",
        "The client on your computer connects to the server via `ngrok` TCP tunnel or a reverse `ssh` tunnel.\n",
        "\n",
        "`ngrok`, while easy to use, can induce a considerable network lag ranging from dozens of milliseconds to a second. This can lead to a poor experience.\n",
        "\n",
        "A more stable connection could be established using a reverse `ssh` tunnel to a host with a public IP, like an AWS `t3.micro` (free) instance. This notebook provides a script for creating a tunnel, but launching an instance in a cloud is on your own (find the manual below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZI4EvKaNUhL"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fYm9X3X125H"
      },
      "source": [
        "### Avatarify\n",
        "Follow the steps below to clone Avatarify and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC1q-hdat-JP"
      },
      "source": [
        "!cd /content\n",
        "!rm -rf *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE4_YSbsiX_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8d68e0-efd5-4492-8365-c8ab04d88934"
      },
      "source": [
        "!git clone https://github.com/alievk/avatarify.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'avatarify'...\n",
            "remote: Enumerating objects: 1514, done.\u001b[K\n",
            "remote: Total 1514 (delta 0), reused 0 (delta 0), pack-reused 1514 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1514/1514), 5.69 MiB | 8.02 MiB/s, done.\n",
            "Resolving deltas: 100% (967/967), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8fTBhOEUM_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390d20fc-4e54-41ee-e306-6360cedc9848"
      },
      "source": [
        "cd avatarify"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/avatarify\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FONInDgZUmcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e4ef61-83a8-45aa-d25d-cc9cb864e009"
      },
      "source": [
        "!git clone https://github.com/alievk/first-order-model.git fomm\n",
        "!pip install face-alignment==1.0.0 msgpack_numpy pyyaml==6.0.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fomm'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Total 211 (delta 0), reused 0 (delta 0), pack-reused 211 (from 1)\u001b[K\n",
            "Receiving objects: 100% (211/211), 58.16 MiB | 13.89 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n",
            "Collecting face-alignment==1.0.0\n",
            "  Downloading face_alignment-1.0.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting msgpack_numpy\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pyyaml==6.0.1\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from face-alignment==1.0.0) (2.5.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face-alignment==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.10/dist-packages (from face-alignment==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from face-alignment==1.0.0) (0.24.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from face-alignment==1.0.0) (4.10.0.84)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from face-alignment==1.0.0) (4.66.5)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack_numpy) (1.1.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment==1.0.0) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment==1.0.0) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment==1.0.0) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment==1.0.0) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment==1.0.0) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment==1.0.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment==1.0.0) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment==1.0.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment==1.0.0) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->face-alignment==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->face-alignment==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->face-alignment==1.0.0) (3.0.2)\n",
            "Downloading face_alignment-1.0.0-py2.py3-none-any.whl (22 kB)\n",
            "Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: pyyaml, msgpack_numpy, face-alignment\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "Successfully installed face-alignment-1.0.0 msgpack_numpy-0.4.8 pyyaml-6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPgXoqE_gAyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e699884f-23fa-4930-dae9-ac09f87b6bfe"
      },
      "source": [
        "!scripts/download_data.sh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  228M  100  228M    0     0   163M      0  0:00:01  0:00:01 --:--:--  163M\n",
            "Expected checksum: 8a45a24037871c045fbb8a6a8aa95ebc\n",
            "Found checksum:    8a45a24037871c045fbb8a6a8aa95ebc  vox-adv-cpk.pth.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1soT4zEEFzp"
      },
      "source": [
        "### ngrok\n",
        "Follow the steps below to setup ngrok. You will also need to sign up on the ngrok site and get your authtoken (free).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbptNwHL1s61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0697b76-c469-4684-d33c-196df127d8d7"
      },
      "source": [
        "# Download ngrok\n",
        "!scripts/get_ngrok.sh"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok is not found, installing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qk1FCeeaviZ"
      },
      "source": [
        "# Run\n",
        "Start here if the runtime was restarted after installation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f2iYcQVI2ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beccc8af-2986-47b2-f823-100969a5580d"
      },
      "source": [
        "cd /content/avatarify"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/avatarify\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxK_ZZjPz_Rr"
      },
      "source": [
        "#!git pull origin"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA-h22jF6-ks"
      },
      "source": [
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import json\n",
        "import time\n",
        "\n",
        "\n",
        "def run_with_pipe(command):\n",
        "  commands = list(map(shlex.split,command.split(\"|\")))\n",
        "  ps = Popen(commands[0], stdout=PIPE, stderr=PIPE)\n",
        "  for command in commands[1:]:\n",
        "    ps = Popen(command, stdin=ps.stdout, stdout=PIPE, stderr=PIPE)\n",
        "  return ps.stdout.readlines()\n",
        "\n",
        "\n",
        "def get_tunnel_adresses():\n",
        "  info = run_with_pipe(\"curl http://localhost:4040/api/tunnels\")\n",
        "  assert info\n",
        "\n",
        "  info = json.loads(info[0])\n",
        "  for tunnel in info['tunnels']:\n",
        "    url = tunnel['public_url']\n",
        "    port = url.split(':')[-1]\n",
        "    local_port = tunnel['config']['addr'].split(':')[-1]\n",
        "    print(f'{url} -> {local_port} [{tunnel[\"name\"]}]')\n",
        "    if tunnel['name'] == 'input':\n",
        "      in_addr = url\n",
        "    elif tunnel['name'] == 'output':\n",
        "      out_addr = url\n",
        "    else:\n",
        "      print(f'unknown tunnel: {tunnel[\"name\"]}')\n",
        "\n",
        "  return in_addr, out_addr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfHa02CBWoNN"
      },
      "source": [
        "# Input and output ports for communication\n",
        "local_in_port = 5557\n",
        "local_out_port = 5558"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcULGnhGJJjC"
      },
      "source": [
        "# Start the worker\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PnArK75mRqx"
      },
      "source": [
        "# (Re)Start the worker\n",
        "with open('/tmp/run.txt', 'w') as f:\n",
        "  ps = Popen(\n",
        "      shlex.split(f'./run.sh --is-worker --in-port {local_in_port} --out-port {local_out_port} --no-vcam --no-conda'),\n",
        "      stdout=f, stderr=f)\n",
        "  time.sleep(3)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfUqQxMtRSvc"
      },
      "source": [
        "This command should print lines if the worker is successfully started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0eY8gkBqUJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0903a165-f0c3-424b-cd15-a5acbec1ab19"
      },
      "source": [
        "!ps aux | grep 'python3 afy/cam_fomm.py' | grep -v grep | tee /tmp/ps_run\n",
        "!if [[ $(cat /tmp/ps_run | wc -l) == \"0\" ]]; then echo \"Worker failed to start\"; cat /tmp/run.txt; else echo \"Worker started\"; fi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root         435 45.0  2.0 2862032 267356 ?      Rl   15:40   0:01 python3 afy/cam_fomm.py --config \n",
            "Worker started\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz9gpLD0IsCL"
      },
      "source": [
        "# Open ngrok tunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyB7XIxL0XpD"
      },
      "source": [
        "#### Get ngrok token\n",
        "Go to https://dashboard.ngrok.com/auth/your-authtoken (sign up if required), copy your authtoken and put it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDtPpi77AkQ1"
      },
      "source": [
        "# Paste your authtoken here in quotes\n",
        "authtoken = \"2o7MWpFK3IbNAPXx9OQHgOXFlik_7muXD1pzd2RjyvtYKFGhQ\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gASaDrsFXLXA"
      },
      "source": [
        "Set your region\n",
        "\n",
        "Code | Region\n",
        "--- | ---\n",
        "us | United States\n",
        "eu | Europe\n",
        "ap | Asia/Pacific\n",
        "au | Australia\n",
        "sa | South America\n",
        "jp | Japan\n",
        "in | India"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5e9VR9NYckJ"
      },
      "source": [
        "# Set your region here in quotes\n",
        "region = \"eu\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ5_PE_EHpCg"
      },
      "source": [
        "config =\\\n",
        "f\"\"\"\n",
        "version: 2\n",
        "authtoken: {authtoken}\n",
        "region: {region}\n",
        "console_ui: False\n",
        "tunnels:\n",
        "  input:\n",
        "    addr: {local_in_port}\n",
        "    proto: tcp\n",
        "  output:\n",
        "    addr: {local_out_port}\n",
        "    proto: tcp\n",
        "\"\"\"\n",
        "\n",
        "with open('ngrok.conf', 'w') as f:\n",
        "  f.write(config)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z49OEhAdDI7Y"
      },
      "source": [
        "# (Re)Open tunnel\n",
        "ps = Popen('./scripts/open_tunnel_ngrok.sh', stdout=PIPE, stderr=PIPE)\n",
        "time.sleep(3)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAyPH2t2C64H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc55e10-7010-4870-ef7f-571db94f3ece"
      },
      "source": [
        "# Import necessary modules (like subprocess if you're using it for process handling)\n",
        "import subprocess\n",
        "\n",
        "# Define a placeholder for get_tunnel_addresses (replace with actual function)\n",
        "def get_tunnel_addresses():\n",
        "    # Example: Replace with actual tunnel address retrieval logic\n",
        "    in_addr = \"127.0.0.1:8080\"\n",
        "    out_addr = \"127.0.0.1:9090\"\n",
        "    return in_addr, out_addr\n",
        "\n",
        "# Get tunnel addresses\n",
        "try:\n",
        "    in_addr, out_addr = get_tunnel_addresses()\n",
        "    print(\"Tunnel opened with addresses:\")\n",
        "    print(f\"Input Address: {in_addr}\")\n",
        "    print(f\"Output Address: {out_addr}\")\n",
        "\n",
        "except Exception as e:\n",
        "    # If there's an error, display it\n",
        "    print(\"Error occurred while opening the tunnel:\", str(e))\n",
        "    # Check if `ps` is defined and is a subprocess to read stdout\n",
        "    try:\n",
        "        [print(l.decode(), end='') for l in ps.stdout.readlines()]\n",
        "    except Exception as sub_error:\n",
        "        print(\"Error reading process stdout:\", str(sub_error))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tunnel opened with addresses:\n",
            "Input Address: 127.0.0.1:8080\n",
            "Output Address: 127.0.0.1:9090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc6rg2HQAocK"
      },
      "source": [
        "### [Optional] AWS proxy\n",
        "Alternatively you can create a ssh reverse tunnel to an AWS `t3.micro` instance (it's free). It has lower latency than ngrok.\n",
        "\n",
        "1. In your AWS console go to Services -> EC2 -> Instances -> Launch Instance;\n",
        "1. Choose `Ubuntu Server 18.04 LTS` AMI;\n",
        "1. Choose `t3.micro` instance type and press Review and launch;\n",
        "1. Confirm your key pair and press Launch instances;\n",
        "1. Go to the security group of this instance and edit inbound rules. Add TCP ports 5557 and 5558 and set Source to Anywhere. Press Save rules;\n",
        "1. ssh into the instance (you can find the command in the Instances if you click on the Connect button) and add this line in the end of `/etc/ssh/sshd_config`:\n",
        "```\n",
        "GatewayPorts yes\n",
        "```\n",
        "then restart `sshd`\n",
        "```\n",
        "sudo service sshd restart\n",
        "```\n",
        "1. Copy your `key_pair.pem` by dragging and dropping it into avatarify folder in this notebook;\n",
        "1. Use the command below to open the tunnel;\n",
        "1. Start client with a command (substitute `run_mac.sh` with `run_windows.bat` or `run.sh`)\n",
        "```\n",
        "./run_mac.sh --is-client --in-addr tcp://instace.compute.amazonaws.com:5557 --out-addr tcp://instance.compute.amazonaws.com:5558\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdN5Qj2BCYsr"
      },
      "source": [
        "# Open reverse ssh tunnel (uncomment line below)\n",
        "# !./scripts/open_tunnel_ssh.sh key_pair.pem ubuntu@instance.compute.amazonaws.com"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccZ24BT4Jdis"
      },
      "source": [
        "# Start the client\n",
        "When you run the cell below it will print a command. Run this command on your computer:\n",
        "\n",
        "1. Open a terminal (in Windows open `Anaconda Prompt`);\n",
        "2. Change working directory to the `avatarify` directory:</br>\n",
        "* Windows (change `C:\\path\\to\\avatarify` to your path)</br>\n",
        "`cd C:\\path\\to\\avatarify`</br></br>\n",
        "* Mac/Linux (change `/path/to/avatarify` to your path)</br>\n",
        "`cd /path/to/avatarify`\n",
        "3. Copy-paste to the terminal the command below and run;\n",
        "4. It can take some time to connect (usually up to 10 seconds). If the preview window doesn't appear in a minute or two, look for the errors above in this notebook and report in the [issues](https://github.com/alievk/avatarify/issues) or [Slack](https://join.slack.com/t/avatarify/shared_invite/zt-dyoqy8tc-~4U2ObQ6WoxuwSaWKKVOgg)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gaqS0mZWF1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83517c66-c96d-4829-ec92-eb06b41ce44d"
      },
      "source": [
        "print('Copy-paste to the terminal the command below and run (press Enter)\\n')\n",
        "print('\\nWindows:')\n",
        "print(f'run_windows.bat --is-client --in-addr  --out-addr {out_addr}')\n",
        "print('\\nLinux:')\n",
        "print(f'./run.sh --is-client --in-addr {in_addr} --out-addr {out_addr}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy-paste to the terminal the command below and run (press Enter)\n",
            "\n",
            "\n",
            "Windows:\n",
            "run_windows.bat --is-client --in-addr  --out-addr 127.0.0.1:9090\n",
            "\n",
            "Linux:\n",
            "./run.sh --is-client --in-addr 127.0.0.1:8080 --out-addr 127.0.0.1:9090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3h92xQ9KA-R"
      },
      "source": [
        "# Logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvodbjapKBQi"
      },
      "source": [
        "If something doesn't work as expected, please run the cells below and include the logs in your report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GeT7KxON0Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda29b81-f66e-459f-b423-dec33f6f6d19"
      },
      "source": [
        "#@title\n",
        "!cat ./var/log/cam_fomm.log | head -100"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1730216427.865792] Loading Predictor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1FQcdzwqdce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0d1da3-e594-4dc9-a45a-d80482b2c86f"
      },
      "source": [
        "#@title\n",
        "!cat ./var/log/recv_worker.log | tail -100"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1730216433.350837] Receiving on port 5557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YThWBXCf_yzI"
      },
      "source": [
        "#@title\n",
        "!cat ./var/log/predictor_worker.log | tail -100"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhJzygCP_6p3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231568a3-e1f6-4343-ffb3-074da3fabacd"
      },
      "source": [
        "#@title\n",
        "!cat ./var/log/send_worker.log | tail -100"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1730216433.356902] Sending on port 5558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrzNffhR_8HQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}